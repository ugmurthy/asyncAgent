# LLM Provider Configuration
# Choose one: openai | openrouter | openrouter-fetch | ollama
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o

# OpenRouter Configuration
# Use 'openrouter' for SDK-based (OpenAI SDK) or 'openrouter-fetch' for native Fetch API
OPENROUTER_API_KEY=sk-or-your-key-here
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet

# Ollama Configuration (local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# Fallback model (used if provider-specific model not set)
LLM_MODEL=gpt-4o

# Server Configuration
PORT=3000
HOST=0.0.0.0
NODE_ENV=development

# Database
DATABASE_PATH=./data/async-agent.db

# Agent Configuration
DEFAULT_STEP_BUDGET=20
DEFAULT_TOOL_TIMEOUT=60000
MAX_CONCURRENT_RUNS=3
MAX_MESSAGE_LENGTH=1000

# Email Configuration (optional)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=
SMTP_PASS=
SMTP_FROM=

# Security
API_KEY=
WEBHOOK_SECRET=

# Logging
LOG_LEVEL=info
